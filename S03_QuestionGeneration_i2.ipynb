{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the sync code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "import json\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "clientDS = OpenAI(api_key=os.environ['DEEPSEEK_API_KEY'],base_url=\"https://api.deepseek.com\")\n",
    "clientNV = OpenAI(api_key=os.environ['NVIDIA_API_KEY'],base_url=\"https://integrate.api.nvidia.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Industrial_Gas_Turbines_AMY_Razak.json',\n",
       " 'msd_servo_drive.json',\n",
       " 'pcs7_compendium_part_a_en-US_en-US.json',\n",
       " 'pcs7_compendium_part_b_en-US_en-US.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dir = './S02_SemanticChunkedJson/'\n",
    "lsjson = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "lsjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcs7_compendium_part_a_en-US_en-US.json 0 116\n"
     ]
    }
   ],
   "source": [
    "i=2\n",
    "\n",
    "jsonName = lsjson[i]\n",
    "# READ JSON\n",
    "jsonPath = json_dir + jsonName\n",
    "with open(jsonPath) as f:\n",
    "    nodes_json = json.load(f) \n",
    "# CREATE FOLDER IF NOT EXISTS\n",
    "folderName = jsonName.replace('.json','')\n",
    "if not os.path.exists(f\"./S03_QuestionGeneration/{folderName}/\"):\n",
    "    os.makedirs(f\"./S03_QuestionGeneration/{folderName}/\")\n",
    "# CONVERT TO LLAMA NODES\n",
    "nodes = [TextNode.from_dict(node_dict) for node_dict in nodes_json]\n",
    "# LOOP GEN QUESTION\n",
    "for j in range(len(nodes)):\n",
    "    # PARSE\n",
    "    nodej = nodes[j]\n",
    "    node_file_name = nodej.metadata['file_name']\n",
    "    node_hash = nodej.hash\n",
    "    node_text = nodej.text\n",
    "    print(jsonName,j,len(nodes))\n",
    "    # ONLY WORK IF NOT ALREADY EXISTS\n",
    "    if not os.path.isfile(f\"./S03_QuestionGeneration/{folderName}/{j}_{node_hash}.csv\"):\n",
    "        # BUILD PROMPT\n",
    "        system_prompt = f\"\"\"\n",
    "        ### TASK ###\n",
    "        User will provide chunked text from semantic chunking from the documents.\n",
    "        Generate 10 diverse questions (factual, inferential, or analytical) based on the input text.\n",
    "        For each question, provide 5 correct answers with different answering styles (e.g., concise, detailed, rephrased, or structured differently).\n",
    "        Ensure all answers are factually accurate and derived from the input text.\n",
    "        Try to reference the book name if it makes sense to do so, note that there could be multiple books for reference, \n",
    "        so try to be specific if generating something about the book/publisher/inside the book\n",
    "\n",
    "        ### BAD QUESTION EXAMPLE ###\n",
    "        Bad Question1: What rights does the author assert in the book?\n",
    "        Correct way1: What rights does the author assert in the book '--bookname--'?\n",
    "        Bad Question2: What does the CD-ROM included with the book contain?\n",
    "        Correct way2: What does the CD-ROM included with the book '--bookname--' contain?\n",
    "        Bad Question3: What type of information sources does the book use?\n",
    "        Correct way3: What type of information sources does the book '--bookname--' use?\n",
    "\n",
    "        \"\"\"\n",
    "        system_prompt += '''\n",
    "        ### EXAMPLE JSON OUTPUT ###\n",
    "        {\n",
    "            'OUT1':{'Q':'generated Question',\n",
    "                    'A1':'generated Answer Style1',\n",
    "                    'A2':'generated Answer Style2',\n",
    "                    'A3':'generated Answer Style3',\n",
    "                    'A4':'generated Answer Style4',\n",
    "                    'A5':'generated Answer Style5'},\n",
    "            'OUT2':{'Q':'generated Question',\n",
    "                    'A1':'generated Answer Style1',\n",
    "                    'A2':'generated Answer Style2',\n",
    "                    'A3':'generated Answer Style3',\n",
    "                    'A4':'generated Answer Style4',\n",
    "                    'A5':'generated Answer Style5'},\n",
    "            ...\n",
    "            'OUT10':{'Q':'generated Question',\n",
    "                    'A1':'generated Answer Style1',\n",
    "                    'A2':'generated Answer Style2',\n",
    "                    'A3':'generated Answer Style3',\n",
    "                    'A4':'generated Answer Style4',\n",
    "                    'A5':'generated Answer Style5'}\n",
    "        }\n",
    "        '''\n",
    "        user_text = node_text\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_text}]\n",
    "        # CALL API\n",
    "        response = clientDS.chat.completions.create(model=\"deepseek-chat\",\n",
    "                                                    messages=messages,\n",
    "                                                    response_format={'type': 'json_object'})\n",
    "        response_json = json.loads(response.choices[0].message.content)\n",
    "        # STORE IN DF\n",
    "        df = pd.DataFrame.from_dict(response_json, orient='index').reset_index(drop=True)\n",
    "        df['NODE_FILE_NAME'] = node_file_name\n",
    "        df['NODE_NUMBER'] = j\n",
    "        df['NODE_HASH'] = node_hash\n",
    "        df['NODE_TEXT'] = node_text\n",
    "        df = df[['NODE_FILE_NAME','NODE_NUMBER','NODE_HASH','NODE_TEXT',\n",
    "                'Q','A1','A2','A3','A4','A5']]\n",
    "        df.to_csv(f\"./S03_QuestionGeneration/{folderName}/{j}_{node_hash}.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"What are the main components of an industrial gas turbine as mentioned in the book 'Industrial Gas Turbines: Performance and Operability' by A. M. Y Razak?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'The main components include a heat exchanger, combustor, compressor, gas supply, and heat sinks.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# messages = [{\"role\": \"user\", \"content\": response_json['OUT1']['Q']},\n",
    "#             {\"role\": \"assistant\", \"content\": response_json['OUT1']['A1']}]\n",
    "# response = clientNV.chat.completions.create(model=\"nvidia/nemotron-4-340b-reward\", messages=messages)\n",
    "# # response.choices[0].logprobs.content\n",
    "# def get_scores_from_response(openai_response_template):\n",
    "#     logprobs = openai_response_template.choices[0].logprobs.content\n",
    "#     score_dict = {}\n",
    "#     for score in logprobs:\n",
    "#         score_dict[score.token] = score.logprob\n",
    "#     return score_dict\n",
    "# get_scores_from_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_response_and_scores(client, model, question, response_content):\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": question\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"assistant\",\n",
    "#             \"content\": response_content\n",
    "#         },\n",
    "#     ]\n",
    "\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         messages=messages,\n",
    "#     )\n",
    "\n",
    "#     scores = get_scores_from_response(response)\n",
    "#     return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-tonk-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
