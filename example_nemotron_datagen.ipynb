{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE MOCKUP Q AND A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_GENERATION_PROMPT_TEMPLATE = \"\"\"Given the following topic, generate a list of {n_subtopics} subtopics that are related to the topic.\n",
    "The topic is: {topic}\n",
    "The list must be without numbers, and without any description of the subtopics. The subtopics should be separated by a comma. There must be no other text than the list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PROMPT_TEMPLATE = \"\"\"Given the following topic, generate {n_questions} questions that could be asked about that topic. Your response should be in a list format.\n",
    "The topic is: {sub_topic}\n",
    "The list must be without numbers. The questions should be separated by a newline character. There must be no other text than the list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_PROMPT_TEMPLATE = \"\"\"Given a question, generate 2 responses that could be given to that question. Your response should be in a list format.\n",
    "The question is: {question}\n",
    "\n",
    "The list must be in the format:\n",
    "\n",
    "RESPONSE A: Response A text here\n",
    "RESPONSE B: Response B text here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "nvidia_api_key = os.getenv('NVIDIA_API_KEY')\n",
    "print(nvidia_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=\"https://integrate.api.nvidia.com/v1\", api_key=nvidia_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Computer Science\"\n",
    "n_subtopics = 3\n",
    "n_questions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subtopics(client, topic, n_subtopics):\n",
    "    prompt = TOPIC_GENERATION_PROMPT_TEMPLATE.format(topic=topic, n_subtopics=n_subtopics)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = generate_subtopics(client, topic=topic, n_subtopics=n_subtopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Structures, Algorithms, Artificial Intelligence\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(responses.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Structures', 'Algorithms', 'Artificial Intelligence']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtopic_list = [x.strip() for x in responses.choices[0].message.content.split(\",\")]\n",
    "subtopic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(client, sub_topic, n_questions):\n",
    "    prompt = QUESTION_PROMPT_TEMPLATE.format(sub_topic=sub_topic, n_questions=n_questions)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_generator(client, subtopic_list, n_question):\n",
    "    question_list = [generate_questions(client, subtopic, n_question) for subtopic in tqdm(subtopic_list)]\n",
    "    return question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:09<00:00,  3.15s/it]\n"
     ]
    }
   ],
   "source": [
    "question_list = question_generator(client, subtopic_list, n_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the key differences between array and linked list data structures?\\n\\nCan you explain the concept of a hash table and its advantages in data storage and retrieval?\\n',\n",
       " 'What are some of the most common types of algorithms used in computer science?\\n\\nCan you explain how algorithms are used in everyday applications, such as social media or search engines?\\n',\n",
       " 'What are the potential benefits and risks of artificial intelligence for society?\\n\\nHow can we ensure that the development and use of artificial intelligence is ethical and unbiased?\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list_formatted = []\n",
    "\n",
    "for question_set in question_list:\n",
    "    question_list_formatted += question_set.split(\"\\n\")\n",
    "\n",
    "question_list_formatted = [x for x in question_list_formatted if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the key differences between array and linked list data structures?',\n",
       " 'Can you explain the concept of a hash table and its advantages in data storage and retrieval?',\n",
       " 'What are some of the most common types of algorithms used in computer science?',\n",
       " 'Can you explain how algorithms are used in everyday applications, such as social media or search engines?',\n",
       " 'What are the potential benefits and risks of artificial intelligence for society?',\n",
       " 'How can we ensure that the development and use of artificial intelligence is ethical and unbiased?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_list_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(client, question):\n",
    "    prompt = RESPONSE_PROMPT_TEMPLATE.format(question=question)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\" : \"user\",\n",
    "             \"content\" : prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_generator(client, question_list):\n",
    "    response_list = [generate_responses(client, question) for question in tqdm(question_list)]\n",
    "    return response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:07<00:00, 11.19s/it]\n"
     ]
    }
   ],
   "source": [
    "question_response_list = response_generator(client, question_list_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response_pair_list = []\n",
    "for question, response_set in zip(question_list_formatted, question_response_list):\n",
    "    question_response_pair_list.append(\n",
    "        {\n",
    "            \"question\" : question,\n",
    "            \"responses\" : {\n",
    "                \"response_a\" : {\"response\" : response_set.split(\"RESPONSE B:\")[0].replace(\"RESPONSE A:\", \"\").strip()},\n",
    "                \"response_b\" : {\"response\" : response_set.split(\"RESPONSE B:\")[-1].split(\"\\n\\n\")[0].strip()}\n",
    "            },\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What are the key differences between array and linked list data structures?',\n",
       "  'responses': {'response_a': {'response': 'One key difference between array and linked list data structures is that arrays have a fixed size, while linked lists can grow or shrink in size dynamically. Additionally, arrays allow for constant time access to any element by index, whereas linked lists require sequential access from the head or tail, resulting in linear time complexity for accessing an element by index.'},\n",
       "   'response_b': {'response': 'Another difference between array and linked list data structures is that arrays are stored contiguously in memory, which can lead to issues with memory allocation and fragmentation. Linked lists, on the other hand, are stored non-contiguously, with each node containing a pointer to the next node. This allows for easy insertion and deletion of elements, but can result in additional memory overhead due to the need to store pointers.'}}},\n",
       " {'question': 'Can you explain the concept of a hash table and its advantages in data storage and retrieval?',\n",
       "  'responses': {'response_a': {'response': 'A hash table is a data structure that maps keys to values using a hash function. The hash function takes a key as input and returns an index in the hash table where the corresponding value can be stored or retrieved. Hash tables provide fast insertion, deletion, and lookup operations, typically with an average time complexity of O(1). They are particularly useful when dealing with large datasets and require quick access to data based on a unique key.'},\n",
       "   'response_b': {'response': 'A hash table is a type of data storage that uses a hash function to compute an index into an array of buckets or slots, from which the desired value can be found. The main advantages of using hash tables for data storage and retrieval include efficient search, insert, and delete operations, as well as the ability to handle collisions effectively. Hash tables are ideal for implementing associative arrays, databases, and caches, where quick access to data based on a key is essential.'}}},\n",
       " {'question': 'What are some of the most common types of algorithms used in computer science?',\n",
       "  'responses': {'response_a': {'response': 'Some of the most common types of algorithms used in computer science include sorting algorithms, such as quicksort, mergesort, and heapsort, which are used to arrange data in a specific order.'},\n",
       "   'response_b': {'response': \"In computer science, graph algorithms like Dijkstra's algorithm and the A* algorithm are widely used for finding the shortest path between two nodes in a graph. Additionally, search algorithms like depth-first search and breadth-first search are commonly used for traversing and searching through data structures.\"}}},\n",
       " {'question': 'Can you explain how algorithms are used in everyday applications, such as social media or search engines?',\n",
       "  'responses': {'response_a': {'response': 'Algorithms are used in everyday applications like social media to personalize user experience. For instance, they analyze user behavior, preferences, and interactions to curate a tailored feed, suggest friends or content, and deliver targeted advertisements.'},\n",
       "   'response_b': {'response': 'Search engines utilize algorithms to provide relevant search results. When a user enters a query, the algorithm scours the web, indexes pages, and ranks them based on factors like keyword relevance, site reputation, and user engagement. This ensures that the most useful and high-quality results appear at the top of the search page.'}}},\n",
       " {'question': 'What are the potential benefits and risks of artificial intelligence for society?',\n",
       "  'responses': {'response_a': {'response': 'Artificial intelligence has the potential to bring numerous benefits to society, such as increased efficiency and productivity in various industries, improved healthcare through personalized medicine and early disease detection, and enhanced safety in transportation with the development of self-driving cars. However, there are also risks associated with AI, including job displacement due to automation, the possibility of AI being used for malicious purposes like cyberattacks or autonomous weapons, and ethical concerns around privacy and bias in AI decision-making.'},\n",
       "   'response_b': {'response': 'AI can significantly contribute to societal progress by enabling breakthroughs in scientific research, providing more accurate weather forecasts, and facilitating better resource management. On the other hand, AI also poses risks, such as exacerbating social inequality if access to AI technology is limited to certain groups, the potential for AI to reinforce and amplify existing biases in data, and the challenge of ensuring transparency and accountability in AI systems, which could lead to a lack of trust and understanding among the public.'}}},\n",
       " {'question': 'How can we ensure that the development and use of artificial intelligence is ethical and unbiased?',\n",
       "  'responses': {'response_a': {'response': 'To ensure ethical and unbiased AI development and use, we can follow these steps: 1) Establish clear ethical guidelines and regulations for AI development, 2) Promote diversity in AI development teams to minimize unconscious biases, 3) Regularly audit AI systems for bias and fairness, and 4) Encourage transparency in AI algorithms and decision-making processes.'},\n",
       "   'response_b': {'response': 'Here are some ways to ensure ethical and unbiased AI: 1) Implement robust data governance to prevent biased data from being used in AI training, 2) Foster a culture of ethical awareness and responsibility among AI developers and users, 3) Engage in ongoing education and training on AI ethics and bias mitigation techniques, and 4) Collaborate with stakeholders, including the public, to ensure AI systems align with societal values and expectations.'}}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_response_pair_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Nemotron-4 340B Reward to Generate a Preference Dataset\n",
    "Equipped with a dataset that has questions that have response pairs, a preference dataset that is compatible with DPO training, SteerLM reward model training, and RLHF reward model training can be generated straightforwardly thanks to [Nemotron-4 340B Reward](https://build.nvidia.com/nvidia/nemotron-4-340b-reward) available through [build.nvidia.com](https://build.nvidia.com/explore/discover)!\n",
    "\n",
    "First, an example of how to use the endpoint.\n",
    "\n",
    "1. You must both provide a user message, and an assistant message!\n",
    "2. It will return a chat-style message with the scores, as well as the scores in the logprogs parameter.\n",
    "\n",
    "The response package will include scores related to five attributes:\n",
    "\n",
    "1. Helpfulness: Overall helpfulness of the response to the prompt.\n",
    "2. Correctness: Inclusion of all pertinent facts without errors.\n",
    "3. Coherence: Consistency and clarity of expression.\n",
    "4. Complexity: Intellectual depth required to write response (i.e. whether the response can be written by anyone with basic language competency or requires deep domain expertise).\n",
    "5. Verbosity: Amount of detail included in the response, relative to what is asked for in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\" : \"Hello!\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Hello! How can I help you today?\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=\"nvidia/nemotron-4-340b-reward\", messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='559708ee-9b60-42c8-a87f-2eaaf158b443', choices=[Choice(finish_reason='length', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=4.09375, top_logprobs=[]), ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=4.03125, top_logprobs=[]), ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=4.25, top_logprobs=[]), ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.5703125, top_logprobs=[]), ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.109375, top_logprobs=[])], refusal=None), message=[ChatCompletionMessage(content='helpfulness:4.09375,correctness:4.03125,coherence:4.25,complexity:0.5703125,verbosity:1.109375', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)])], created=None, model=None, object=None, service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=54, total_tokens=55, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionTokenLogprob(token='helpfulness', bytes=None, logprob=4.09375, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='correctness', bytes=None, logprob=4.03125, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='coherence', bytes=None, logprob=4.25, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='complexity', bytes=None, logprob=0.5703125, top_logprobs=[]),\n",
       " ChatCompletionTokenLogprob(token='verbosity', bytes=None, logprob=1.109375, top_logprobs=[])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].logprobs.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_from_response(openai_response_template):\n",
    "    logprobs = openai_response_template.choices[0].logprobs.content\n",
    "    score_dict = {}\n",
    "    for score in logprobs:\n",
    "        score_dict[score.token] = score.logprob\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'helpfulness': 4.09375,\n",
       " 'correctness': 4.03125,\n",
       " 'coherence': 4.25,\n",
       " 'complexity': 0.5703125,\n",
       " 'verbosity': 1.109375}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores_from_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_and_scores(client, model, question, response_content):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": response_content\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    scores = get_scores_from_response(response)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question_response_pairs(client, model, question_response_score_list):\n",
    "    results = []\n",
    "\n",
    "    for question_response_pair in tqdm(question_response_score_list):\n",
    "        question = question_response_pair[\"question\"]\n",
    "        resp_a = get_response_and_scores(client, model, question, question_response_pair[\"responses\"][\"response_a\"][\"response\"])\n",
    "        resp_b = get_response_and_scores(client, model, question, question_response_pair[\"responses\"][\"response_b\"][\"response\"])\n",
    "        results.append((resp_a, question_response_pair, \"response_a\"))\n",
    "        results.append((resp_b, question_response_pair, \"response_b\"))\n",
    "\n",
    "    for result, question_response_pair, response_key in results:\n",
    "        question_response_pair[\"responses\"][response_key].update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "question_response_score_list = question_response_pair_list.copy()\n",
    "process_question_response_pairs(client, \"nvidia/nemotron-4-340b-reward\", question_response_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the key differences between array and linked list data structures?',\n",
       " 'responses': {'response_a': {'response': 'One key difference between array and linked list data structures is that arrays have a fixed size, while linked lists can grow or shrink in size dynamically. Additionally, arrays allow for constant time access to any element by index, whereas linked lists require sequential access from the head or tail, resulting in linear time complexity for accessing an element by index.',\n",
       "   'helpfulness': 3.421875,\n",
       "   'correctness': 3.3125,\n",
       "   'coherence': 3.859375,\n",
       "   'complexity': 1.8671875,\n",
       "   'verbosity': 1.0859375},\n",
       "  'response_b': {'response': 'Another difference between array and linked list data structures is that arrays are stored contiguously in memory, which can lead to issues with memory allocation and fragmentation. Linked lists, on the other hand, are stored non-contiguously, with each node containing a pointer to the next node. This allows for easy insertion and deletion of elements, but can result in additional memory overhead due to the need to store pointers.',\n",
       "   'helpfulness': 2.140625,\n",
       "   'correctness': 2.28125,\n",
       "   'coherence': 3.5,\n",
       "   'complexity': 1.8203125,\n",
       "   'verbosity': 1.25}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_response_score_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'synthetic_data_with_scores_filtered-{threshold}.jsonl', 'w') as f:\n",
    "    for item in question_response_score_list:\n",
    "        question = item[\"question\"]\n",
    "        response_a = item[\"responses\"][\"response_a\"]\n",
    "        response_b = item[\"responses\"][\"response_b\"]\n",
    "        response_a[\"question\"] = question\n",
    "        response_b[\"question\"] = question\n",
    "        if response_a[\"helpfulness\"] < threshold and response_b[\"helpfulness\"] < threshold:\n",
    "            continue\n",
    "        f.write(json.dumps(response_a))\n",
    "        f.write('\\n')\n",
    "        f.write(json.dumps(response_b))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-tonk-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
