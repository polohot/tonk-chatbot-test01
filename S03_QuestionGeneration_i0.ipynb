{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the sync code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import json\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "# clientDS  = OpenAI(api_key=os.environ['DEEPSEEK_API_KEY'], base_url=\"https://api.deepseek.com\")\n",
    "# clientNV  = OpenAI(api_key=os.environ['NVIDIA_API_KEY'], base_url=\"https://integrate.api.nvidia.com/v1\")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "gpt_35_llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Industrial_Gas_Turbines_AMY_Razak.json',\n",
       " 'msd_servo_drive.json',\n",
       " 'pcs7_compendium_part_a_en-US_en-US.json',\n",
       " 'pcs7_compendium_part_b_en-US_en-US.json']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dir = './S02_SemanticChunkedJson/'\n",
    "lsjson = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "lsjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industrial_Gas_Turbines_AMY_Razak.json 0 381\n",
      "Industrial_Gas_Turbines_AMY_Razak.json 1 381\n",
      "Industrial_Gas_Turbines_AMY_Razak.json 2 381\n",
      "Industrial_Gas_Turbines_AMY_Razak.json 3 381\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "\n",
    "jsonName = lsjson[i]\n",
    "# READ JSON\n",
    "jsonPath = json_dir + jsonName\n",
    "with open(jsonPath) as f:\n",
    "    nodes_json = json.load(f) \n",
    "# CONVERT TO LLAMA NODES\n",
    "nodes = [TextNode.from_dict(node_dict) for node_dict in nodes_json]\n",
    "# CREATE FOLDER IF NOT EXISTS\n",
    "folderName = jsonName.replace('.json','')\n",
    "if not os.path.exists(f\"./S03_QuestionGeneration/{folderName}/\"):\n",
    "    os.makedirs(f\"./S03_QuestionGeneration/{folderName}/\")\n",
    "# LOOP GEN QUESTION\n",
    "for j in range(len(nodes)):\n",
    "    # PARSE\n",
    "    nodej = nodes[j]\n",
    "    node_file_name = nodej.metadata['file_name']\n",
    "    node_hash = nodej.hash\n",
    "    node_text = nodej.text\n",
    "    print(jsonName,j,len(nodes))\n",
    "    # ONLY WORK IF NOT ALREADY EXISTS\n",
    "    if not os.path.isfile(f\"./S03_QuestionGeneration/{folderName}/{j}_{node_hash}.csv\"):\n",
    "        # INIT DATASET GENERATOR\n",
    "        dataset_generator = RagDatasetGenerator.from_documents(documents=[nodes[j]],\n",
    "                                                                llm=gpt_35_llm,\n",
    "                                                                num_questions_per_chunk=20,\n",
    "                                                                show_progress=False)\n",
    "        # REPLACE QUERY\n",
    "        str_query = f\"\"\"\n",
    "        You are a Teacher/ Professor. Your task is to setup a quiz/examination.\n",
    "        Using the provided context, formulate {dataset_generator.num_questions_per_chunk} that captures an important fact from the context. \n",
    "        You MUST obey the following criteria:\n",
    "        - Restrict the question to the context information provided.\n",
    "        - Do NOT create a question that cannot be answered from the context.\n",
    "        - Phrase the question so that it does NOT refer to specific context. For instance, do NOT put phrases like \"given provided context\" or \"in this work\" in the question, because if the question is asked elsewhere it wouldn't be provided specific context. Replace these terms with specific details.\n",
    "\n",
    "        BAD questions:\n",
    "        - What did the author do in his childhood\n",
    "        - What were the main findings in this report\n",
    "\n",
    "        GOOD questions:\n",
    "        - What did Barack Obama do in his childhood\n",
    "        - What were the main findings in the original Transformers paper by Vaswani et al.\n",
    "\n",
    "        Skills Focus: Consider questions that test:\n",
    "        - Application of Knowledge: How can students use what they have learned in practical scenarios?\n",
    "        - Critical Thinking: Can they analyze or evaluate different concepts?\n",
    "        - Technical Skills: Can they demonstrate proficiency with tools, systems, or frameworks covered in the content?\n",
    "\n",
    "        Generate the questions below:\n",
    "        \"\"\"\n",
    "        dataset_generator.question_gen_query = str_query\n",
    "        # GENERATE QUESTIONS\n",
    "        rag_dataset = dataset_generator.generate_dataset_from_nodes()\n",
    "        # SAVE DATASET\n",
    "        df = rag_dataset.to_pandas()\n",
    "        df['NODE_FILE_NAME'] = node_file_name\n",
    "        df['NODE_NUMBER'] = j\n",
    "        df['NODE_HASH'] = node_hash\n",
    "        df['NODE_TEXT'] = node_text\n",
    "        df = df[['NODE_FILE_NAME','NODE_NUMBER','NODE_HASH','query','reference_answer',]]\n",
    "        df = df.rename(columns={'query':'QUESTION','reference_answer':'ANSWER'})\n",
    "        df.to_csv(f\"./S03_QuestionGeneration/{folderName}/{j}_{node_hash}.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_response_and_scores(client, model, question, response_content):\n",
    "#     messages = [\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": question\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"assistant\",\n",
    "#             \"content\": response_content\n",
    "#         },\n",
    "#     ]\n",
    "\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=model,\n",
    "#         messages=messages,\n",
    "#     )\n",
    "\n",
    "#     scores = get_scores_from_response(response)\n",
    "#     return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-tonk-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
