{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFReader\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnstructuredReader\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_hub\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfile\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpymu_pdf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyMuPDFReader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_hub'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from llama_hub.file.pdf.base import PDFReader\n",
    "from llama_hub.file.unstructured.base import UnstructuredReader\n",
    "from llama_hub.file.pymu_pdf.base import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILES = [\"./S00_RawPdfs/Industrial Gas Turbines AMY_Razak.pdf\"]\n",
    "VAL_FILES = [\"./S00_RawPdfs/Industrial Gas Turbines AMY_Razak.pdf\"]\n",
    "\n",
    "TRAIN_CORPUS_FPATH = \"./tmp/train_corpus.json\"\n",
    "VAL_CORPUS_FPATH = \"./tmp/val_corpus.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(files, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files {files}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=files)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "    parser = SentenceSplitter()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files ['./S00_RawPdfs/Industrial Gas Turbines AMY_Razak.pdf']\n",
      "Loaded 625 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 625/625 [00:00<00:00, 2450.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 625 nodes\n",
      "Loading files ['./S00_RawPdfs/Industrial Gas Turbines AMY_Razak.pdf']\n",
      "Loaded 625 docs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 625/625 [00:00<00:00, 2422.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 625 nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_nodes = load_corpus(TRAIN_FILES, verbose=True)\n",
    "val_nodes = load_corpus(VAL_FILES, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = DeepSeek(model=\"deepseek-chat\", api_key=os.environ['DEEPSEEK_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:14<02:07, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:25<01:39, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:35<01:18, 11.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:43<01:00, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:54<00:51, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [01:03<00:40, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [01:13<00:29, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [01:22<00:19,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [01:31<00:09,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:40<00:00,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [01:50,  9.55s/it]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [02:00,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [02:09,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [02:17,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [02:28,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = generate_qa_embedding_pairs(train_nodes[:20], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.6.0+cu126 available.\n",
      "PyTorch version 2.6.0+cu126 available.\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en\n",
      "Load pretrained SentenceTransformer: BAAI/bge-small-en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\AdMiN\\AppData\\Local\\llama_index\\models\\models--BAAI--bge-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.finetuning.embeddings.adapter:Use pytorch device: cuda\n",
      "Use pytorch device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.finetuning import EmbeddingAdapterFinetuneEngine\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "import torch\n",
    "\n",
    "base_embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n",
    "\n",
    "finetune_engine = EmbeddingAdapterFinetuneEngine(\n",
    "    train_dataset,\n",
    "    base_embed_model,\n",
    "    model_output_path=\"model_output_test\",\n",
    "    # bias=True,\n",
    "    epochs=4,\n",
    "    verbose=True,\n",
    "    # optimizer_class=torch.optim.SGD,\n",
    "    # optimizer_params={\"lr\": 0.01}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> Prepared optimizer, scheduler, and loss model.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 0] Current loss: 1.4269917011260986\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.04it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.51it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 0] Current loss: 2.1348814964294434\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.64it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.34it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.13it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 0] Current loss: 1.959083914756775\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.62it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.03it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.55it/s]\n",
      "Iteration: 100%|██████████| 4/4 [00:01<00:00,  2.21it/s]\n",
      "Epoch:  25%|██▌       | 1/4 [00:01<00:05,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 0] Current loss: 1.9531528949737549\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.13it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.13it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.13it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.32it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.34it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 1] Current loss: 1.419250249862671\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 1] Current loss: 2.1301395893096924\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.45it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 95.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 1] Current loss: 1.955467939376831\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.47it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.04it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.56it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.11it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "Iteration: 100%|██████████| 4/4 [00:01<00:00,  2.47it/s]\n",
      "Epoch:  50%|█████     | 2/4 [00:03<00:03,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 1] Current loss: 1.9494880437850952\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.08it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.14it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.02it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.89it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.32it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 2] Current loss: 1.41213059425354\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.28it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.01it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 99.99it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.34it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 91.18it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.35it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.97it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.32it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.34it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.71it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 2] Current loss: 2.1272857189178467\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 51.23it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 46.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.34it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.37it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.71it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 2] Current loss: 1.9530417919158936\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 13.55it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.42it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.24it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.32it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.24it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.30it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.60it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.39it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.36it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.21it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.76it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 22.21it/s]\n",
      "Iteration: 100%|██████████| 4/4 [00:02<00:00,  1.47it/s]\n",
      "Epoch:  75%|███████▌  | 3/4 [00:06<00:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 2] Current loss: 1.9469257593154907\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.49it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.42it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.32it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 50.00it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.98it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.62it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.95it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.68it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 3] Current loss: 1.4079842567443848\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.42it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 33.33it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 30.30it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 67.53it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.63it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 18.35it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.96it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.38it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.40it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.52it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.50it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.90it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.35it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 21.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 3] Current loss: 2.1256654262542725\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 65.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.92it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.15it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.41it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.34it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 75.60it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 42.79it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 61.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.88it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.34it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.60it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 49.07it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.43it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 3] Current loss: 1.9517393112182617\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.66it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.57it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.54it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 14.59it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.79it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.73it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.20it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.67it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 31.40it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 58.83it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.37it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.17it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.82it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.46it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.44it/s]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.04it/s]\n",
      "Iteration: 100%|██████████| 4/4 [00:03<00:00,  1.32it/s]\n",
      "Epoch: 100%|██████████| 4/4 [00:09<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34m> [Epoch 3] Current loss: 1.9456815719604492\n",
      "\u001b[0m\u001b[1;3;34m> Finished training, saving to model_output_test\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.embeddings.adapter.base:Use pytorch device: cuda\n",
      "Use pytorch device: cuda\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LinearAdapterEmbeddingModel' from 'llama_index.core.embeddings' (c:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\core\\embeddings\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m embed_model = finetune_engine.get_finetuned_model()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# alternatively import model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearAdapterEmbeddingModel\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# embed_model = LinearAdapterEmbeddingModel(base_embed_model, \"model_output_test\")\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'LinearAdapterEmbeddingModel' from 'llama_index.core.embeddings' (c:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\core\\embeddings\\__init__.py)"
     ]
    }
   ],
   "source": [
    "embed_model = finetune_engine.get_finetuned_model()\n",
    "\n",
    "# alternatively import model\n",
    "from llama_index.core.embeddings import LinearAdapterEmbeddingModel\n",
    "\n",
    "# embed_model = LinearAdapterEmbeddingModel(base_embed_model, \"model_output_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/625 [00:09<1:37:12,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.deepseek.com/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/625 [00:15<2:44:29, 15.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_dataset = \u001b[43mgenerate_qa_embedding_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m val_dataset = generate_qa_embedding_pairs(val_nodes, llm=llm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\finetuning\\embeddings\\common.py:144\u001b[39m, in \u001b[36mgenerate_qa_embedding_pairs\u001b[39m\u001b[34m(nodes, llm, qa_generate_prompt_tmpl, num_questions_per_chunk, retry_limit, on_failure, save_every, output_path, verbose)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m retry_count < retry_limit:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         success = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\llms\\openai_like\\base.py:136\u001b[39m, in \u001b[36mOpenAILike.complete\u001b[39m\u001b[34m(self, prompt, formatted, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m formatted:\n\u001b[32m    134\u001b[39m     prompt = \u001b[38;5;28mself\u001b[39m.completion_to_prompt(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:322\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    324\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    325\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:431\u001b[39m, in \u001b[36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[39m\u001b[34m(_self, *args, **kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m event_id = callback_manager.on_event_start(\n\u001b[32m    423\u001b[39m     CBEventType.LLM,\n\u001b[32m    424\u001b[39m     payload={\n\u001b[32m   (...)\u001b[39m\u001b[32m    428\u001b[39m     },\n\u001b[32m    429\u001b[39m )\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     f_return_val = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    433\u001b[39m     callback_manager.on_event_end(\n\u001b[32m    434\u001b[39m         CBEventType.LLM,\n\u001b[32m    435\u001b[39m         payload={EventPayload.EXCEPTION: e},\n\u001b[32m    436\u001b[39m         event_id=event_id,\n\u001b[32m    437\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:404\u001b[39m, in \u001b[36mOpenAI.complete\u001b[39m\u001b[34m(self, prompt, formatted, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    403\u001b[39m     complete_fn = \u001b[38;5;28mself\u001b[39m._complete\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplete_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\core\\base\\llms\\generic_utils.py:173\u001b[39m, in \u001b[36mchat_to_completion_decorator.<locals>.wrapper\u001b[39m\u001b[34m(prompt, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, **kwargs: Any) -> CompletionResponse:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# normalize input\u001b[39;00m\n\u001b[32m    172\u001b[39m     messages = prompt_to_messages(prompt)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     chat_response = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# normalize output\u001b[39;00m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_response_to_completion_response(chat_response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:107\u001b[39m, in \u001b[36mllm_retry_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    100\u001b[39m retry = create_retry_decorator(\n\u001b[32m    101\u001b[39m     max_retries=max_retries,\n\u001b[32m    102\u001b[39m     random_exponential=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m     max_seconds=\u001b[32m20\u001b[39m,\n\u001b[32m    106\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    334\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    335\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    473\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    374\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\tenacity\\__init__.py:398\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    399\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    480\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\llama_index\\llms\\openai\\base.py:475\u001b[39m, in \u001b[36mOpenAI._chat\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    469\u001b[39m message_dicts = to_openai_message_dicts(\n\u001b[32m    470\u001b[39m     messages,\n\u001b[32m    471\u001b[39m     model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    472\u001b[39m )\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reuse_client:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_model_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    913\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\openai\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\openai\\_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\openai\\_base_client.py:955\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m    952\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, request.method, request.url)\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    961\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpx\\_client.py:928\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    927\u001b[39m     response.close()\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpx\\_client.py:922\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpx\\_models.py:881\u001b[39m, in \u001b[36mResponse.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    877\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[33;03mRead and return the response content.\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_content\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m     \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpx\\_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpx\\_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpx\\_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AdMiN\\miniconda3\\envs\\py312-tonk-chatbot\\Lib\\ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_dataset = generate_qa_embedding_pairs(train_nodes, llm=llm)\n",
    "val_dataset = generate_qa_embedding_pairs(val_nodes, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-tonk-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
